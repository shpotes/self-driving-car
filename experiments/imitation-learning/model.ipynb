{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda, Concatenate, AveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from utils import decode_netout, compute_overlap, compute_ap\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from preprocessing import BatchGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from backend import TinyYoloFeature, MobileNetFeature, SqueezeNetFeature\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vehicle(object):\n",
    "    def __init__(self, backend,\n",
    "                       input_size, \n",
    "                       labels,\n",
    "                       actions,\n",
    "                       ob_weights,\n",
    "                       max_box_per_image=50,\n",
    "                       anchors=[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]):\n",
    "\n",
    "        self.input_size = input_size        \n",
    "        self.labels = list(labels)\n",
    "        self.actions = list(actions)\n",
    "        self.nb_moves = len(self.actions)\n",
    "        self.nb_class = len(self.labels)\n",
    "        self.nb_box = len(anchors)//2\n",
    "        self.class_wt = np.ones(self.nb_class, dtype='float32')\n",
    "        self.anchors = anchors\n",
    "\n",
    "        self.max_box_per_image = max_box_per_image\n",
    "        \n",
    "        self.losses = {\n",
    "            \"obj_output\": self.yolo_loss,\n",
    "            \"dir_output\": \"categorical_crossentropy\",\n",
    "        }\n",
    "    \n",
    "        self.lossWeights = {\"obj_output\": 5.0,\n",
    "                            \"dir_output\": 1.0}\n",
    "        ##########################\n",
    "        # Make the model\n",
    "        ##########################\n",
    "\n",
    "        # make the feature extractor layers\n",
    "        input_image     = Input(shape=(self.input_size, self.input_size, 3))\n",
    "        self.true_boxes = Input(shape=(1, 1, 1, max_box_per_image , 4))  \n",
    "\n",
    "        if backend == 'SqueezeNet':\n",
    "            self.feature_extractor = SqueezeNetFeature(self.input_size)        \n",
    "        elif backend == 'MobileNet':\n",
    "            self.feature_extractor = MobileNetFeature(self.input_size)\n",
    "        elif backend == 'Tiny Yolo':\n",
    "            self.feature_extractor = TinyYoloFeature(self.input_size)\n",
    "        else:\n",
    "            raise Exception('Architecture not supported! Only support Tiny Yolo, MobileNet, SqueezeNet at the moment!')\n",
    "\n",
    "        print(self.feature_extractor.get_output_shape())    \n",
    "        self.grid_h, self.grid_w = self.feature_extractor.get_output_shape()        \n",
    "        features = self.feature_extractor.extract(input_image)            \n",
    "        print(self.feature_extractor.get_output_shape())\n",
    "        # make the object detection layer\n",
    "        output = Conv2D(self.nb_box * (4 + 1 + self.nb_class), \n",
    "                        (1,1), strides=(1,1), \n",
    "                        padding='same', \n",
    "                        name='DetectionLayer', \n",
    "                        kernel_initializer='lecun_normal')(features)\n",
    "        output = Reshape((self.grid_h, self.grid_w, self.nb_box, 4 + 1 + self.nb_class))(output)\n",
    "        output = Lambda(lambda args: args[0], name='obj_output')([output, self.true_boxes])\n",
    "\n",
    "        \n",
    "        \n",
    "        convdir  = Conv2D(2, (3, 3), activation='relu', padding='same', use_bias=False, name='dir1')(input_image)\n",
    "        convdir2 = Conv2D(2, (3, 3), activation='relu', padding='same', use_bias=False, name='dir2')(convdir)\n",
    "        pooldir = MaxPooling2D(pool_size=2, name='dir3')(convdir2)\n",
    "        \n",
    "        convdir1  = Conv2D(4, (3, 3), activation='relu', padding='same', use_bias=False, name='dir4')(pooldir)\n",
    "        convdir12 = Conv2D(4, (3, 3), activation='relu', padding='same', use_bias=False, name='dir5')(convdir1)\n",
    "        pooldir1 = AveragePooling2D(pool_size=2, name='dir6')(convdir12)\n",
    "        \n",
    "        flat1 = Flatten()(pooldir1)\n",
    "        flat2 = Flatten()(output)\n",
    "        \n",
    "        added = Concatenate()([flat1, flat2])\n",
    "        \n",
    "        #fc1 = Dense(32, activation='relu', name='fchingona')(added)\n",
    "        fc2 = Dense(6, activation='relu', name='dir_output')(added)\n",
    "        \n",
    "        self.model = Model([input_image, self.true_boxes], [output, fc2])\n",
    "        \n",
    "        self.model.load_weights(ob_weights, by_name=True)\n",
    "\n",
    "        # print a summary of the whole model\n",
    "        self.model.summary()\n",
    "        \n",
    "    def yolo_loss(self, y_true, y_pred):\n",
    "        mask_shape = tf.shape(y_true)[:4]\n",
    "        \n",
    "        cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(self.grid_w), [self.grid_h]), (1, self.grid_h, self.grid_w, 1, 1)))\n",
    "        cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "        cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [self.batch_size, 1, 1, self.nb_box, 1])\n",
    "        \n",
    "        coord_mask = tf.zeros(mask_shape)\n",
    "        conf_mask  = tf.zeros(mask_shape)\n",
    "        class_mask = tf.zeros(mask_shape)\n",
    "        \n",
    "        seen = tf.Variable(0.)\n",
    "        total_recall = tf.Variable(0.)\n",
    "        \n",
    "        \"\"\"\n",
    "        Adjust prediction\n",
    "        \"\"\"\n",
    "        ### adjust x and y      \n",
    "        pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "        \n",
    "        ### adjust w and h\n",
    "        pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(self.anchors, [1,1,1,self.nb_box,2])\n",
    "        \n",
    "        ### adjust confidence\n",
    "        pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "        \n",
    "        ### adjust class probabilities\n",
    "        pred_box_class = y_pred[..., 5:]\n",
    "        \n",
    "        \"\"\"\n",
    "        Adjust ground truth\n",
    "        \"\"\"\n",
    "        ### adjust x and y\n",
    "        true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "        \n",
    "        ### adjust w and h\n",
    "        true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "        \n",
    "        ### adjust confidence\n",
    "        true_wh_half = true_box_wh / 2.\n",
    "        true_mins    = true_box_xy - true_wh_half\n",
    "        true_maxes   = true_box_xy + true_wh_half\n",
    "        \n",
    "        pred_wh_half = pred_box_wh / 2.\n",
    "        pred_mins    = pred_box_xy - pred_wh_half\n",
    "        pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "        \n",
    "        intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        \n",
    "        true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "        pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "        union_areas = pred_areas + true_areas - intersect_areas\n",
    "        iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "        \n",
    "        true_box_conf = iou_scores * y_true[..., 4]\n",
    "        \n",
    "        ### adjust class probabilities\n",
    "        true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "        \n",
    "        \"\"\"\n",
    "        Determine the masks\n",
    "        \"\"\"\n",
    "        ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "        coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * self.coord_scale\n",
    "        \n",
    "        ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "        # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "        true_xy = self.true_boxes[..., 0:2]\n",
    "        true_wh = self.true_boxes[..., 2:4]\n",
    "        \n",
    "        true_wh_half = true_wh / 2.\n",
    "        true_mins    = true_xy - true_wh_half\n",
    "        true_maxes   = true_xy + true_wh_half\n",
    "        \n",
    "        pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "        pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "        \n",
    "        pred_wh_half = pred_wh / 2.\n",
    "        pred_mins    = pred_xy - pred_wh_half\n",
    "        pred_maxes   = pred_xy + pred_wh_half    \n",
    "        \n",
    "        intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        \n",
    "        true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "        pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "        union_areas = pred_areas + true_areas - intersect_areas\n",
    "        iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "        best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "        conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * self.no_object_scale\n",
    "        \n",
    "        # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "        conf_mask = conf_mask + y_true[..., 4] * self.object_scale\n",
    "        \n",
    "        ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "        class_mask = y_true[..., 4] * tf.gather(self.class_wt, true_box_class) * self.class_scale       \n",
    "        \n",
    "        \"\"\"\n",
    "        Warm-up training\n",
    "        \"\"\"\n",
    "        no_boxes_mask = tf.to_float(coord_mask < self.coord_scale/2.)\n",
    "        seen = tf.assign_add(seen, 1.)\n",
    "        \n",
    "        true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, 1), \n",
    "                              lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
    "                                       true_box_wh + tf.ones_like(true_box_wh) * \\\n",
    "                                       np.reshape(self.anchors, [1,1,1,self.nb_box,2]) * \\\n",
    "                                       no_boxes_mask, \n",
    "                                       tf.ones_like(coord_mask)],\n",
    "                              lambda: [true_box_xy, \n",
    "                                       true_box_wh,\n",
    "                                       coord_mask])\n",
    "        \n",
    "        \"\"\"\n",
    "        Finalize the loss\n",
    "        \"\"\"\n",
    "        nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "        nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "        nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "        \n",
    "        loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "        loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "        loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "        loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "        loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "        \n",
    "        loss = tf.cond(tf.less(seen, 1), \n",
    "                      lambda: loss_xy + loss_wh + loss_conf + loss_class + 10,\n",
    "                      lambda: loss_xy + loss_wh + loss_conf + loss_class)\n",
    "        \n",
    "        if self.debug:\n",
    "            nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
    "            nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
    "            \n",
    "            current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
    "            total_recall = tf.assign_add(total_recall, current_recall) \n",
    "\n",
    "            loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
    "            loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
    "            loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
    "            loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
    "            loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
    "            loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
    "            loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def train(self, train_imgs,     # the list of images to train the model\n",
    "                    valid_imgs,     # the list of images used to validate the model\n",
    "                    nb_epochs,      # number of epoches\n",
    "                    learning_rate,  # the learning rate\n",
    "                    batch_size,     # the size of the batch\n",
    "                    object_scale,\n",
    "                    no_object_scale,\n",
    "                    coord_scale,\n",
    "                    class_scale,\n",
    "                    saved_weights_name='best_weights.h5',\n",
    "                    debug=False):     \n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.object_scale    = object_scale\n",
    "        self.no_object_scale = no_object_scale\n",
    "        self.coord_scale     = coord_scale\n",
    "        self.class_scale     = class_scale\n",
    "\n",
    "        self.debug = debug\n",
    "\n",
    "        ############################################\n",
    "        # Make train and validation generators\n",
    "        ############################################\n",
    "\n",
    "        generator_config = {\n",
    "            'IMAGE_H'         : self.input_size, \n",
    "            'IMAGE_W'         : self.input_size,\n",
    "            'GRID_H'          : self.grid_h,  \n",
    "            'GRID_W'          : self.grid_w,\n",
    "            'BOX'             : self.nb_box,\n",
    "            'LABELS'          : self.labels,\n",
    "            'CLASS'           : len(self.labels),\n",
    "            'ACTIONS'         : self.actions,\n",
    "            'MOVES'           : len(self.actions),\n",
    "            'ANCHORS'         : self.anchors,\n",
    "            'BATCH_SIZE'      : self.batch_size,\n",
    "            'TRUE_BOX_BUFFER' : self.max_box_per_image,\n",
    "        }    \n",
    "\n",
    "        train_generator = BatchGenerator(train_imgs, \n",
    "                                     generator_config, \n",
    "                                     norm=self.feature_extractor.normalize)\n",
    "        valid_generator = BatchGenerator(valid_imgs, \n",
    "                                     generator_config, \n",
    "                                     norm=self.feature_extractor.normalize,\n",
    "                                     jitter=False) \n",
    "\n",
    "        ############################################\n",
    "        # Compile the model\n",
    "        ############################################\n",
    "\n",
    "        optimizer = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "        self.model.compile(loss=self.losses, loss_weights=self.lossWeights, optimizer=optimizer)\n",
    "        \n",
    "        ############################################\n",
    "        # Make a few callbacks\n",
    "        ############################################\n",
    "\n",
    "        early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=0.001, \n",
    "                           patience=3, \n",
    "                           mode='min', \n",
    "                           verbose=1)\n",
    "        \n",
    "        checkpoint = ModelCheckpoint(saved_weights_name, \n",
    "                                     monitor='val_loss', \n",
    "                                     verbose=1, \n",
    "                                     save_best_only=True, \n",
    "                                     mode='min', \n",
    "                                     period=1)\n",
    "\n",
    "        tensorboard = TensorBoard(log_dir=os.path.expanduser('~/logs/'), \n",
    "                                  histogram_freq=0, \n",
    "                                  #write_batch_performance=True,\n",
    "                                  write_graph=True, \n",
    "                                  write_images=False)\n",
    "\n",
    "        ############################################\n",
    "        # Start the training process\n",
    "        ############################################        \n",
    "\n",
    "        self.model.fit_generator(generator        = train_generator, \n",
    "                                 steps_per_epoch  = len(train_generator), \n",
    "                                 epochs           = nb_epochs, \n",
    "                                 verbose          = 2 if debug else 1,\n",
    "                                 validation_data  = valid_generator,\n",
    "                                 validation_steps = len(valid_generator),\n",
    "                                 callbacks        = [early_stop, checkpoint, tensorboard])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/santiago/anaconda3/envs/vehicle/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(15, 15)\n",
      "(15, 15)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dir1 (Conv2D)                   (None, 256, 256, 2)  54          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dir2 (Conv2D)                   (None, 256, 256, 2)  36          dir1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 15, 15, 512)  722496      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dir3 (MaxPooling2D)             (None, 128, 128, 2)  0           dir2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "DetectionLayer (Conv2D)         (None, 15, 15, 100)  51300       model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dir4 (Conv2D)                   (None, 128, 128, 4)  72          dir3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 15, 15, 10, 1 0           DetectionLayer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 1, 1, 10,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dir5 (Conv2D)                   (None, 128, 128, 4)  144         dir4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "obj_output (Lambda)             (None, 15, 15, 10, 1 0           reshape_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dir6 (AveragePooling2D)         (None, 64, 64, 4)    0           dir5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16384)        0           dir6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 22500)        0           obj_output[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 38884)        0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dir_output (Dense)              (None, 6)            233310      concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,007,412\n",
      "Trainable params: 1,007,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import json, random, pickle\n",
    "\n",
    "with open('config.json') as config_buffer:    \n",
    "    config = json.loads(config_buffer.read())\n",
    "    \n",
    "#train_imgs = parse_annotation(config['train']['train_annot_folder'], \n",
    "#                              config['train']['train_image_folder'])\n",
    "\n",
    "\n",
    "model = Vehicle(backend = config['model']['backend'],\n",
    "            input_size = config['model']['input_size'],\n",
    "            labels = config['model']['labels'], \n",
    "            actions = config['model']['actions'],\n",
    "            ob_weights = config['model']['ob_weights'],\n",
    "            max_box_per_image = config['model']['max_box_per_image'],\n",
    "            anchors = config['model']['anchors'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.     ,   0.     ,   0.     ,   0.     , 196.41937,   0.     ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
